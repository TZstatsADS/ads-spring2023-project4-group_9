{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76754c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../data/compas-scores-two-years.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fc7a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'African-American', 'Caucasian', 'Hispanic',\n",
       "       'Native American', 'Asian'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(data['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76663c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['African-American', 'Caucasian'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter for only African-American and Caucasian\n",
    "data_2race = data.loc[(data['race']=='African-American') | (data['race']=='Caucasian')]\n",
    "pd.unique(data_2race['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef35b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>African-American</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>African-American</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid     sex  age              race  v_decile_score  \\\n",
       "1               1    Male   34  African-American               1   \n",
       "2               1    Male   24  African-American               3   \n",
       "3               0    Male   23  African-American               6   \n",
       "6               1    Male   41         Caucasian               2   \n",
       "8               0  Female   39         Caucasian               1   \n",
       "\n",
       "   priors_count.1  \n",
       "1               0  \n",
       "2               4  \n",
       "3               1  \n",
       "6              14  \n",
       "8               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select a few columns to be used in the following functions\n",
    "selected_columns = [\"two_year_recid\",\"sex\",\"age\",\"race\",\"v_decile_score\",\"priors_count.1\",]\n",
    "data_filtered = data_2race[selected_columns]\n",
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d78754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two_year_recid    0\n",
       "sex               0\n",
       "age               0\n",
       "race              0\n",
       "v_decile_score    0\n",
       "priors_count.1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "data_filtered.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7b82a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(data_filtered['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8059047f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "#replace all string values to 0,1,2...\n",
    "data_filtered[\"race\"].replace(['African-American', 'Caucasian'],[0, 1], inplace=True)\n",
    "data_filtered[\"sex\"].replace(['Male', 'Female'],[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0c5678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid  sex  age  race  v_decile_score  priors_count.1\n",
       "1               1    0   34     0               1               0\n",
       "2               1    0   24     0               3               4\n",
       "3               0    0   23     0               6               1\n",
       "6               1    0   41     1               2              14\n",
       "8               0    1   39     1               1               0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "989d1a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "Accuracy: 0.6721951219512196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#baseline model\n",
    "#logistic regression\n",
    "#model\n",
    "import numpy as np\n",
    "\n",
    "# Define the original dataset\n",
    "X = data_filtered[[\"age\",\"sex\",\"v_decile_score\",\"priors_count.1\"]]\n",
    "y = data_filtered[['two_year_recid']]\n",
    "\n",
    "# Define the sensitive attribute\n",
    "s = data_filtered[[\"race\"]]\n",
    "\n",
    "# Define the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Train the model on the original dataset\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Evaluate the model on the original dataset\n",
    "print(\"Original dataset:\")\n",
    "print(\"Accuracy:\", clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0087d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "443902f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#process data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_filtered_afram = data_filtered[data_filtered['race']==0]\n",
    "data_filtered_cau = data_filtered[data_filtered['race']==1]\n",
    "\n",
    "X_afram = data_filtered_afram[[\"age\",\"sex\",\"v_decile_score\",\"priors_count.1\",\"race\"]]\n",
    "y_afram = data_filtered_afram[['two_year_recid']]\n",
    "\n",
    "X_cau = data_filtered_cau[[\"age\",\"sex\",\"v_decile_score\",\"priors_count.1\",\"race\"]]\n",
    "y_cau = data_filtered_cau[['two_year_recid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40690ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_afram, X_test_afram, y_train_afram, y_test_afram = train_test_split(X_afram, y_afram, test_size=0.2)\n",
    "X_train_cau, X_test_cau, y_train_cau, y_test_cau = train_test_split(X_cau, y_cau, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8162cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorX(X):\n",
    "    return t.tensor(np.array(X)).to(t.float32)\n",
    "\n",
    "def tensorY(X,Y):\n",
    "    return t.from_numpy(np.array(Y).astype('float32')).reshape(X.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2680051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_afram = tensorX(X_train_afram)\n",
    "X_test_afram = tensorX(X_test_afram)\n",
    "X_train_cau = tensorX(X_train_cau)\n",
    "X_test_cau = tensorX(X_test_cau)\n",
    "\n",
    "y_train_afram = tensorY(X_train_afram,y_train_afram)\n",
    "y_test_afram = tensorY(X_test_afram,y_test_afram)\n",
    "y_train_cau = tensorY(X_train_cau,y_train_cau)\n",
    "y_test_cau = tensorY(X_test_cau,y_test_cau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4bcdf1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,data):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.w = nn.Linear(data.shape[1], out_features=1, bias=True)\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        w = self.w(x)\n",
    "        output = self.sigmod(w)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "908030b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRLoss():\n",
    "    def __init__(self, eta=1.0):\n",
    "        super(PRLoss, self).__init__()\n",
    "        self.eta = eta       \n",
    "        \n",
    "    def forward(self,output_a,output_c):\n",
    "        N_a = t.tensor(output_a.shape[0])\n",
    "        N_c   = t.tensor(output_c.shape[0])\n",
    "        Dxisi = t.stack((N_a,N_c),axis=0)\n",
    "        # Pr[y|s]\n",
    "        y_pred_a = t.sum(output_a)\n",
    "        y_pred_c   = t.sum(output_c)\n",
    "        P_ys = t.stack((y_pred_a,y_pred_c),axis=0) / Dxisi\n",
    "        # Pr[y]\n",
    "        P = t.cat((output_a,output_c),0)\n",
    "        P_y = t.sum(P) / (X_train_afram.shape[0]+X_train_cau.shape[0])\n",
    "        # P(siyi)\n",
    "        P_s1y1 = t.log(P_ys[1]) - t.log(P_y)\n",
    "        P_s1y0 = t.log(1-P_ys[1]) - t.log(1-P_y)\n",
    "        P_s0y1 = t.log(P_ys[0]) - t.log(P_y)\n",
    "        P_s0y0 = t.log(1-P_ys[0]) - t.log(1-P_y)\n",
    "        # PI\n",
    "        PI_s1y1 = output_a * P_s1y1\n",
    "        PI_s1y0 =(1- output_a) * P_s1y0\n",
    "        PI_s0y1 = output_c * P_s0y1\n",
    "        PI_s0y0 = (1- output_c )* P_s0y0\n",
    "        PI = t.sum(PI_s1y1) + t.sum(PI_s1y0) + t.sum(PI_s0y1) + t.sum(PI_s0y0)\n",
    "        PI = self.eta * PI\n",
    "        return PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72d9cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_cal(Model_a,Model_c, X_a, y_a, X_c, y_c):\n",
    "    y_pred_a = (Model_a(X_a) >= 0.5)\n",
    "    y_pred_c = (Model_c(X_c) >= 0.5)\n",
    "    accuracy_a  = t.sum(y_pred_a.flatten() == y_a.flatten()) / y_a.shape[0]\n",
    "    accuracy_c  = t.sum(y_pred_c.flatten() == y_c.flatten()) / y_c.shape[0]\n",
    "    accuracy = (accuracy_a + accuracy_c) / 2\n",
    "    cali = t.abs(accuracy_a - accuracy_c)\n",
    "    return round(accuracy.item(),4), round(cali.item(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6bb1770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRLR():\n",
    "  \n",
    "    def __init__(self, eta=0.0, epochs=100, lr = 0.01):\n",
    "        super(PRLR, self).__init__()\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        \n",
    "    def fit(self,X_train_a,y_train_a,X_train_c,y_train_c,\n",
    "            X_test_a, y_test_a, X_test_c, y_test_c):     \n",
    "        model_a = LogisticRegression(X_train_a)\n",
    "        model_c = LogisticRegression(X_train_c)\n",
    "        criterion = nn.BCELoss(reduction='sum')\n",
    "        PI = PRLoss(eta=self.eta)\n",
    "        epochs = self.epochs\n",
    "        #L2 regularization\n",
    "        optimizer = t.optim.Adam(list(model_a.parameters())+ list(model_c.parameters()), self.lr, weight_decay=1e-5)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model_a.train()\n",
    "            model_c.train()\n",
    "            optimizer.zero_grad()\n",
    "            output_a = model_a(X_train_a)\n",
    "            output_c = model_c(X_train_c)\n",
    "            logloss = criterion(output_a, y_train_a)+ criterion(output_c, y_train_c)\n",
    "            PIloss = PI.forward(output_a,output_c)\n",
    "            loss = PIloss +logloss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        model_a.eval()\n",
    "        model_c.eval()\n",
    "        accuracy, calibration = metrics_cal(model_a,model_c,X_test_a, y_test_a, X_test_c, y_test_c)\n",
    "        return accuracy, calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "12edc206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5874, 0.1369)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR = PRLR(eta = 0.7, epochs = 100, lr = 1e-04)\n",
    "PR.fit(X_train_afram,y_train_afram,X_train_cau,y_train_cau, X_test_afram, y_test_afram, X_test_cau, y_test_cau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "PR = PRLR(eta = 0.7, epochs = 100, lr = 1e-04)\n",
    "PR.fit(X_train_afram,y_train_afram,X_train_cau,y_train_cau, X_test_afram, y_test_afram, X_test_cau, y_test_cau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896029c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "82c1ec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-35., -31., -30., ..., -28., -28., -39.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values\n",
    "w = np.zeros(X.shape[1])+1\n",
    "-(X.values).dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "930598ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19608\\4230626874.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Train the model with the Prejudice Remover regularizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mclf_rpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrejudiceRemover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensitive_attr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mclf_rpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Evaluate the model on the original dataset with the Prejudice Remover regularizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19608\\4230626874.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mw0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrpr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m     sf = _prepare_scalar_function(fun, x0, jac, args=args, epsilon=eps,\n\u001b[1;32m-> 1202\u001b[1;33m                                   finite_diff_rel_step=finite_diff_rel_step)\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m--> 262\u001b[1;33m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19608\\4230626874.py\u001b[0m in \u001b[0;36mrpr_loss\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msensitive_attr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msensitive_attr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msensitive_attr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msensitive_attr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpriv\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0munpriv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# Define the Prejudice Remover regularizer\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "class PrejudiceRemover(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, C=1.0, sensitive_attr=None):\n",
    "        self.C = C\n",
    "        self.sensitive_attr = sensitive_attr\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        sensitive_mask = self.sensitive_attr == 1\n",
    "        insenstive_mask = self.sensitive_attr == 0\n",
    "        \n",
    "        # Compute the unprivileged and privileged labels\n",
    "        #print(insenstive_mask)\n",
    "        #print(np.mean(data_filtered[sensitive_mask]['race']))\n",
    "        unpriv = np.mean(data_filtered[insenstive_mask]['race'])\n",
    "        priv = np.mean(data_filtered[sensitive_mask]['race'])\n",
    "        \n",
    "        # Compute the Prejudice Remover regularizer\n",
    "        def rpr_loss(w):\n",
    "            y_pred = 1 / (1 + np.exp(-(X.values).dot(w)))\n",
    "            y_s = y[self.sensitive_attr == 1]\n",
    "            y_ns = y[self.sensitive_attr == 0]\n",
    "            s = self.sensitive_attr[self.sensitive_attr == 1]\n",
    "            ns = self.sensitive_attr[self.sensitive_attr == 0]\n",
    "            pi = np.mean(y_pred[s == 1]) / np.mean(y_pred[s == 0])\n",
    "            loss = -np.sum(np.log(y_pred[y == 1])) + np.sum(np.log(1 - y_pred[y == 0])) + self.C * np.abs(np.log(pi) - np.log(priv / unpriv))\n",
    "            return loss\n",
    "        \n",
    "        # Train the logistic regression model with the Prejudice Remover regularizer\n",
    "        from scipy.optimize import minimize\n",
    "        w0 = np.zeros(X.shape[1])+1\n",
    "        result = minimize(rpr_loss, w0)\n",
    "        self.coef_ = result.x\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = 1 / (1 + np.exp(-X.dot(self.coef_)))\n",
    "        return (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Train the model with the Prejudice Remover regularizer\n",
    "clf_rpr = PrejudiceRemover(sensitive_attr=s)\n",
    "clf_rpr.fit(X, y)\n",
    "\n",
    "# Evaluate the model on the original dataset with the Prejudice Remover regularizer\n",
    "print(\"Prejudice Remover regularizer:\")\n",
    "print(\"Accuracy:\", clf_rpr.score(X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ca8e9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class PrejudiceRemover(LogisticRegression):\n",
    "    def __init__(self, C=1.0, penalty='l2', solver='liblinear', prejudice_factor=1.0):\n",
    "        super().__init__(C=C, penalty=penalty, solver=solver)\n",
    "        self.prejudice_factor = prejudice_factor\n",
    "    \n",
    "    def fit(self, X, y, s):\n",
    "        # Compute the prejudice-free classifier's output\n",
    "        mask_s = np.ones(X.shape[1], dtype=bool)\n",
    "        mask_s[s] = False\n",
    "        clf_pf = LogisticRegression(C=self.C, penalty=self.penalty, solver=self.solver)\n",
    "        clf_pf.fit(X[:, mask_s], y)\n",
    "        y_pf = clf_pf.predict_proba(X[:, mask_s])[:, 1]\n",
    "        \n",
    "        # Add the prejudice remover regularizer to the objective function\n",
    "        n_samples, n_features = X.shape\n",
    "        penalty = np.zeros(n_features)\n",
    "        for j in range(n_features):\n",
    "            if j in s:\n",
    "                # Penalize the classifier for using sensitive attribute j\n",
    "                penalty[j] = self.prejudice_factor * (y_pf - self.predict_proba(X)[:, 1]).dot(X[:, j]) / n_samples\n",
    "        self.penalty_ = penalty\n",
    "        self.coef_ += penalty.reshape(1, -1)\n",
    "        \n",
    "        # Fit the logistic regression model with the prejudice remover regularizer\n",
    "        super().fit(X, y)\n",
    "        \n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "18ce962b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 4 but corresponding boolean dimension is 6150",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19608\\1056015251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"race\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Evaluate the model's performance on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19608\\602827701.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, s)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Compute the prejudice-free classifier's output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mmask_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mmask_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mclf_pf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mclf_pf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_s\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 4 but corresponding boolean dimension is 6150"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from PrejudiceRemover import PrejudiceRemover\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a logistic regression model with the prejudice remover regularizer\n",
    "clf = PrejudiceRemover(C=1.0, penalty='l2', solver='liblinear', prejudice_factor=1.0)\n",
    "\n",
    "s = data_filtered[\"race\"]==1\n",
    "\n",
    "clf.fit(X_train, y_train, s)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c1899986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "6        True\n",
       "8        True\n",
       "        ...  \n",
       "7207    False\n",
       "7208    False\n",
       "7209    False\n",
       "7210    False\n",
       "7212    False\n",
       "Name: race, Length: 6150, dtype: bool"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered[\"race\"]==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5dbba1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sample_weight.shape == (5,), expected (4920,)!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19608\\646789588.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Fit the logistic regression model with prejudice remover regularizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mclf_pr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# Evaluate the performance of both models on the testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1541\u001b[1;33m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1542\u001b[0m             )\n\u001b[0;32m   1543\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     \u001b[0my_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequirements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"W\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m     \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_check_sample_weight\u001b[1;34m(sample_weight, X, dtype, copy)\u001b[0m\n\u001b[0;32m   1565\u001b[0m             raise ValueError(\n\u001b[0;32m   1566\u001b[0m                 \"sample_weight.shape == {}, expected {}!\".format(\n\u001b[1;32m-> 1567\u001b[1;33m                     \u001b[0msample_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m                 )\n\u001b[0;32m   1569\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: sample_weight.shape == (5,), expected (4920,)!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the sensitive attribute (e.g. gender)\n",
    "sensitive_attribute = \"race\"\n",
    "\n",
    "# Define the target variable (e.g. income > $50k)\n",
    "target_variable = \"two_year_recid\"\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = data_filtered.sample(frac=0.8, random_state=1)\n",
    "test_data = data_filtered.drop(train_data.index)\n",
    "\n",
    "# Define the features and labels for the training and testing sets\n",
    "train_features = train_data.drop([sensitive_attribute, target_variable], axis=1)\n",
    "train_labels = train_data[target_variable]\n",
    "test_features = test_data.drop([sensitive_attribute, target_variable], axis=1)\n",
    "test_labels = test_data[target_variable]\n",
    "\n",
    "# Train a logistic regression model without prejudice remover regularizer\n",
    "clf_no_pr = LogisticRegression(solver=\"liblinear\")\n",
    "clf_no_pr.fit(train_features, train_labels)\n",
    "\n",
    "# Train a logistic regression model with prejudice remover regularizer\n",
    "clf_pr = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "# Calculate the prejudice index for the training data\n",
    "pi = []\n",
    "for val in train_data[sensitive_attribute].unique():\n",
    "    pi_val = train_labels[train_data[sensitive_attribute] == val].mean()\n",
    "    pi.append(pi_val)\n",
    "pi_min = min(pi)\n",
    "pi_max = max(pi)\n",
    "\n",
    "# Calculate the prejudice remover regularizer parameter (lambda)\n",
    "lambda_val = (pi_max - pi_min) / 2.0\n",
    "\n",
    "# Create a list of regularization weights (including the prejudice remover regularizer)\n",
    "weights = [1.0] * train_features.shape[1]\n",
    "weights.append(lambda_val)\n",
    "print(train_features.shape[1])\n",
    "\n",
    "# Fit the logistic regression model with prejudice remover regularizer\n",
    "clf_pr.fit(train_features, train_labels, sample_weight=weights)\n",
    "\n",
    "# Evaluate the performance of both models on the testing data\n",
    "acc_no_pr = clf_no_pr.score(test_features, test_labels)\n",
    "acc_pr = clf_pr.score(test_features, test_labels)\n",
    "\n",
    "print(\"Accuracy without prejudice remover: {:.2f}%\".format(acc_no_pr * 100))\n",
    "print(\"Accuracy with prejudice remover: {:.2f}%\".format(acc_pr * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f5807088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
